[
  {
    "episode": 0,
    "timestep": 0,
    "state": [
      4,
      4,
      5,
      5
    ],
    "action": 0,
    "reward": 1.0,
    "q_values_for_state": [
      0.019739392621242885,
      -0.05226737455306823
    ],
    "epsilon": 1.0
  },
  {
    "episode": 0,
    "timestep": 1,
    "state": [
      4,
      4,
      5,
      5
    ],
    "action": 0,
    "reward": 1.0,
    "q_values_for_state": [
      0.11971965322862164,
      -0.05226737455306823
    ],
    "epsilon": 1.0
  },
  {
    "episode": 0,
    "timestep": 2,
    "state": [
      4,
      4,
      5,
      6
    ],
    "action": 1,
    "reward": 1.0,
    "q_values_for_state": [
      0.06007702265484219,
      -0.05857353228438966
    ],
    "epsilon": 1.0
  },
  {
    "episode": 0,
    "timestep": 3,
    "state": [
      4,
      4,
      5,
      5
    ],
    "action": 0,
    "reward": 1.0,
    "q_values_for_state": [
      0.21369531314858886,
      -0.05226737455306823
    ],
    "epsilon": 1.0
  },
  {
    "episode": 0,
    "timestep": 4,
    "state": [
      4,
      4,
      5,
      6
    ],
    "action": 1,
    "reward": 1.0,
    "q_values_for_state": [
      0.06007702265484219,
      0.0684396569457596
    ],
    "epsilon": 1.0
  },
  {
    "episode": 2569,
    "timestep": 90,
    "state": [
      2,
      1,
      6,
      6
    ],
    "action": 0,
    "reward": 1.0,
    "q_values_for_state": [
      0.953860493198142,
      -0.07237793623106488
    ],
    "epsilon": 0.01
  },
  {
    "episode": 2569,
    "timestep": 91,
    "state": [
      2,
      0,
      6,
      7
    ],
    "action": 1,
    "reward": 1.0,
    "q_values_for_state": [
      -0.046860937538845106,
      0.9486905973916056
    ],
    "epsilon": 0.01
  },
  {
    "episode": 2569,
    "timestep": 92,
    "state": [
      2,
      1,
      6,
      7
    ],
    "action": 1,
    "reward": 1.0,
    "q_values_for_state": [
      -0.0033993182670427613,
      0.49739919633608076
    ],
    "epsilon": 0.01
  },
  {
    "episode": 2569,
    "timestep": 93,
    "state": [
      2,
      1,
      7,
      6
    ],
    "action": 0,
    "reward": 1.0,
    "q_values_for_state": [
      0.5418255351021299,
      -0.094369654205427
    ],
    "epsilon": 0.01
  },
  {
    "episode": 2569,
    "timestep": 94,
    "state": [
      2,
      1,
      7,
      7
    ],
    "action": 0,
    "reward": 1.0,
    "q_values_for_state": [
      0.8609185639229175,
      -0.060409877877005184
    ],
    "epsilon": 0.01
  }
]